{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string 01110110 is accepted by the DFA.\n"
     ]
    }
   ],
   "source": [
    "from automata.fa.dfa import DFA\n",
    "\n",
    "# Define the DFA\n",
    "dfa = DFA(\n",
    "    states={'A', 'B', 'C'},\n",
    "    input_symbols={'0', '1'},\n",
    "    transitions={\n",
    "        'A': {'0': 'A', '1': 'B'},\n",
    "        'B': {'0': 'B', '1': 'C'},\n",
    "        'C': {'0': 'C', '1': 'A'}\n",
    "    },\n",
    "    initial_state='A',\n",
    "    final_states={'C'}\n",
    ")\n",
    "\n",
    "# Check if a given string is accepted by the DFA\n",
    "input_str = '01110110'  # Change this string to test different inputs\n",
    "if dfa.accepts_input(input_str):\n",
    "    print(f\"The string {input_str} is accepted by the DFA.\")\n",
    "else:\n",
    "    print(f\"The string {input_str} is not accepted by the DFA.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 strings of length 4 are accepted by the DFA.\n"
     ]
    }
   ],
   "source": [
    "from automata.fa.dfa import DFA\n",
    "from itertools import product\n",
    "\n",
    "# Define the DFA\n",
    "dfa = DFA(\n",
    "    states={'A', 'B', 'C'},\n",
    "    input_symbols={'0', '1'},\n",
    "    transitions={\n",
    "        'A': {'0': 'A', '1': 'B'},\n",
    "        'B': {'0': 'B', '1': 'C'},\n",
    "        'C': {'0': 'C', '1': 'A'}\n",
    "    },\n",
    "    initial_state='A',\n",
    "    final_states={'C'}\n",
    ")\n",
    "\n",
    "# Calculate and print how many strings of length 4 are accepted\n",
    "length = 4\n",
    "count_accepted = 0\n",
    "\n",
    "# Iterate through all possible strings of length 4\n",
    "for s in product(dfa.input_symbols, repeat=length):\n",
    "    input_str = ''.join(s)\n",
    "    if dfa.accepts_input(input_str):\n",
    "        count_accepted += 1\n",
    "\n",
    "print(f\"{count_accepted} strings of length {length} are accepted by the DFA.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regex 0*10*10*(10*10*10*)* matches the DFA for all strings of length 4.\n",
      "The regex (1*0*10*10*)* does NOT match the DFA for all strings of length 4.\n",
      "The regex 0*10*1(0*10*10*1)* does NOT match the DFA for all strings of length 4.\n",
      "The regex (0*1)*(0*10*10*10*)* does NOT match the DFA for all strings of length 4.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re\n",
    "from automata.fa.dfa import DFA\n",
    "\n",
    "# Define the DFA\n",
    "dfa = DFA(\n",
    "    states={'A', 'B', 'C'},\n",
    "    input_symbols={'0', '1'},\n",
    "    transitions={\n",
    "        'A': {'0': 'A', '1': 'B'},\n",
    "        'B': {'0': 'B', '1': 'C'},\n",
    "        'C': {'0': 'C', '1': 'A'}\n",
    "    },\n",
    "    initial_state='A',\n",
    "    final_states={'C'}\n",
    ")\n",
    "\n",
    "# Define the regular expressions\n",
    "regexes = [\n",
    "    r\"0*10*10*(10*10*10*)*\",\n",
    "    r\"(1*0*10*10*)*\",\n",
    "    r\"0*10*1(0*10*10*1)*\",\n",
    "    r\"(0*1)*(0*10*10*10*)*\"\n",
    "]\n",
    "\n",
    "N = 4\n",
    "for regex in regexes:\n",
    "    matches = True\n",
    "    for combination in itertools.product('01', repeat=N):\n",
    "        string = ''.join(combination)\n",
    "        dfa_accepts = dfa.accepts_input(string)\n",
    "        regex_accepts = bool(re.fullmatch(regex, string))\n",
    "        \n",
    "        if dfa_accepts != regex_accepts:\n",
    "            matches = False\n",
    "            break\n",
    "\n",
    "    if matches:\n",
    "        print(f\"The regex {regex} matches the DFA for all strings of length {N}.\")\n",
    "    else:\n",
    "        print(f\"The regex {regex} does NOT match the DFA for all strings of length {N}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NFA does not accept the string '110'.\n"
     ]
    }
   ],
   "source": [
    "from automata.fa.nfa import NFA\n",
    "\n",
    "# Define the NFA\n",
    "nfa = NFA(\n",
    "    states={'A', 'B', 'C'},\n",
    "    input_symbols={'0', '1'},\n",
    "    transitions={\n",
    "        'A': {'0': {'A', 'B'}, '1': {'B'}},\n",
    "        'B': {'0': {'B', 'C'}, '1': {'C'}},\n",
    "        'C': {'0': set(), '1': set()}\n",
    "    },\n",
    "    initial_state='A',\n",
    "    final_states={'C'}\n",
    ")\n",
    "\n",
    "# Input string\n",
    "input_str = \"110\"  # You can change this value to any string you wish to test.\n",
    "\n",
    "if nfa.accepts_input(input_str):\n",
    "    print(f\"The NFA accepts the string '{input_str}'.\")\n",
    "else:\n",
    "    print(f\"The NFA does not accept the string '{input_str}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression 1 does not generate the same language as the NFA\n",
      "Regular expression 2 does not generate the same language as the NFA\n",
      "Regular expression 3 does not generate the same language as the NFA\n",
      "Regular expression 4 does not generate the same language as the NFA\n"
     ]
    }
   ],
   "source": [
    "from automata.fa.nfa import NFA\n",
    "import re\n",
    "\n",
    "# Define the NFA\n",
    "nfa = NFA(\n",
    "    states={'A', 'B', 'C'},\n",
    "    input_symbols={'0', '1'},\n",
    "    transitions={\n",
    "        'A': {'0': {'A', 'B'}, '1': {'B'}},\n",
    "        'B': {'0': {'B', 'C'}, '1': {'C'}},\n",
    "        'C': {}\n",
    "    },\n",
    "    initial_state='A',\n",
    "    final_states={'C'}\n",
    ")\n",
    "\n",
    "# Regular expressions\n",
    "regexes = [\n",
    "    re.compile(\"0*(0+1)0*(0+1)\"),\n",
    "    re.compile(\"(0+1)(0+1)0*\"),\n",
    "    re.compile(\"0*(0+10*)(0+1)\"),\n",
    "    re.compile(\"(0+1)00*|(00*10*)|(0*10*1)\"),  # Updated this line\n",
    "]\n",
    "\n",
    "# Generate all strings of length 4 over {0, 1}\n",
    "strings = [format(i, '04b') for i in range(16)]\n",
    "\n",
    "# Compare NFA with regular expressions\n",
    "for idx, regex in enumerate(regexes):\n",
    "    for s in strings:\n",
    "        nfa_result = nfa.accepts_input(s)\n",
    "        regex_result = bool(regex.fullmatch(s))\n",
    "        if nfa_result != regex_result:\n",
    "            print(f\"Regular expression {idx + 1} does not generate the same language as the NFA\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halts without accepting\n"
     ]
    }
   ],
   "source": [
    "from automata.tm.dtm import DTM\n",
    "from automata.base.exceptions import RejectionException\n",
    "\n",
    "# Define the Turing machine M\n",
    "tm = DTM(\n",
    "    states={'q', 'p', 'f'},\n",
    "    input_symbols={'0', '1'},\n",
    "    tape_symbols={'0', '1', 'B'},\n",
    "    transitions={\n",
    "        'q': {'0': ('p', '0', 'R'), '1': ('p', '0', 'R')},\n",
    "        'p': {'0': ('p', '0', 'R'), '1': ('q', '1', 'L'), 'B': ('f', '0', 'R')},\n",
    "    },\n",
    "    initial_state='q',\n",
    "    blank_symbol='B',\n",
    "    final_states={'f'}\n",
    ")\n",
    "\n",
    "# Test the Turing machine on the given input\n",
    "input_str = ''\n",
    "MAX_STEPS = 10000\n",
    "\n",
    "try:\n",
    "    config_generator = tm.read_input_stepwise(input_str)\n",
    "    for step, config in enumerate(config_generator):\n",
    "        if step > MAX_STEPS:\n",
    "            print('Does not halt')\n",
    "            break\n",
    "    else:\n",
    "        if config.state in tm.final_states:\n",
    "            print('Accepts')\n",
    "        else:\n",
    "            print('Halts without accepting')\n",
    "except RejectionException:\n",
    "    print('Halts without accepting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nullable symbols: ['A']\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import CFG\n",
    "from nltk import CFG\n",
    "\n",
    "# Define the grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> AB | 'b'\n",
    "A -> 'a' A | \n",
    "B -> CD\n",
    "C -> 'b' A | AA\n",
    "D -> AB | BC\n",
    "\"\"\")\n",
    "\n",
    "# Function to find nullable symbols\n",
    "def find_nullable_symbols(grammar):\n",
    "    nullable_symbols = set()\n",
    "    change = True\n",
    "\n",
    "    # Iterate until no new nullable symbols are found\n",
    "    while change:\n",
    "        change = False\n",
    "        for production in grammar.productions():\n",
    "            # If RHS of production is empty or all symbols in RHS are nullable\n",
    "            if all(symbol in nullable_symbols for symbol in production.rhs()):\n",
    "                if production.lhs() not in nullable_symbols:\n",
    "                    nullable_symbols.add(production.lhs())\n",
    "                    change = True\n",
    "\n",
    "    return nullable_symbols\n",
    "\n",
    "nullable_symbols = find_nullable_symbols(grammar)\n",
    "print(\"Nullable symbols:\", [str(symbol) for symbol in nullable_symbols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables that derive a terminal string: ['C', 'S', 'A']\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import CFG, is_nonterminal\n",
    "\n",
    "# Define the grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> AB | 'b'\n",
    "A -> 'a' A | \n",
    "B -> CD\n",
    "C -> 'b' A | AA\n",
    "D -> AB | BC\n",
    "\"\"\")\n",
    "\n",
    "# Function to find variables that derive a terminal string\n",
    "def find_terminal_derivatives(grammar):\n",
    "    terminal_derivatives = set()\n",
    "\n",
    "    # Add all variables that have a production leading directly to a terminal\n",
    "    for production in grammar.productions():\n",
    "        if all(not is_nonterminal(symbol) for symbol in production.rhs()):\n",
    "            terminal_derivatives.add(production.lhs())\n",
    "\n",
    "    # Iterate until no new derivatives are found\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        for production in grammar.productions():\n",
    "            # If all symbols in RHS are either terminal or can derive a terminal string\n",
    "            if all(not is_nonterminal(symbol) or symbol in terminal_derivatives for symbol in production.rhs()):\n",
    "                if production.lhs() not in terminal_derivatives:\n",
    "                    terminal_derivatives.add(production.lhs())\n",
    "                    change = True\n",
    "\n",
    "    return terminal_derivatives\n",
    "\n",
    "terminal_derivatives = find_terminal_derivatives(grammar)\n",
    "print(\"Variables that derive a terminal string:\", [str(symbol) for symbol in terminal_derivatives])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables that appear in some sentential form derived from S: ['S']\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import CFG, is_nonterminal, Production\n",
    "\n",
    "def modify_grammar(grammar, terminal_derivatives):\n",
    "    new_productions = []\n",
    "    \n",
    "    # Iterate through the productions and keep only those that involve symbols that derive a terminal string\n",
    "    for production in grammar.productions():\n",
    "        if all(not is_nonterminal(symbol) or symbol in terminal_derivatives for symbol in production.rhs()):\n",
    "            new_productions.append(production)\n",
    "\n",
    "    # Create a new grammar with the modified productions\n",
    "    modified_grammar = CFG(grammar.start(), new_productions)\n",
    "    return modified_grammar\n",
    "\n",
    "def find_derivable_variables(grammar):\n",
    "    derivable_variables = set()\n",
    "    derivable_variables.add(grammar.start())\n",
    "\n",
    "    # Iterate until no new derivable variables are found\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        for production in grammar.productions():\n",
    "            # If the LHS is derivable\n",
    "            if production.lhs() in derivable_variables:\n",
    "                # Add all RHS nonterminals to the derivable set\n",
    "                for symbol in production.rhs():\n",
    "                    if is_nonterminal(symbol) and symbol not in derivable_variables:\n",
    "                        derivable_variables.add(symbol)\n",
    "                        change = True\n",
    "\n",
    "    return derivable_variables\n",
    "\n",
    "# Find the variables that derive a terminal string\n",
    "terminal_derivatives = find_terminal_derivatives(grammar)\n",
    "\n",
    "# Modify the grammar\n",
    "modified_grammar = modify_grammar(grammar, terminal_derivatives)\n",
    "\n",
    "# Find the derivable variables using the modified grammar\n",
    "derivable_variables = find_derivable_variables(modified_grammar)\n",
    "print(\"Variables that appear in some sentential form derived from S:\", [str(symbol) for symbol in derivable_variables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string abab is NOT in the language L(G).\n",
      "The string baba is NOT in the language L(G).\n",
      "The string baabb is NOT in the language L(G).\n",
      "The string  is NOT in the language L(G).\n"
     ]
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "from nltk.parse import ChartParser\n",
    "\n",
    "# Define the grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> 'A' 'B'\n",
    "    A -> 'B' 'A' | 'a'\n",
    "    B -> 'b' 'A'\n",
    "    A -> \n",
    "\"\"\")\n",
    "\n",
    "# Initialize a parser with the given grammar\n",
    "parser = ChartParser(grammar)\n",
    "\n",
    "# List of strings to test\n",
    "strings = [\"abab\", \"baba\", \"baabb\", \"\"]\n",
    "\n",
    "# Check which strings can be parsed by the grammar\n",
    "for s in strings:\n",
    "    if any(parser.parse(s)):\n",
    "        print(f\"The string {s} is DEFINITELY in the language L(G).\")\n",
    "    else:\n",
    "        print(f\"The string {s} is NOT in the language L(G).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'baB' is not valid in the grammar.\n",
      "'Baa' is not valid in the grammar.\n",
      "'aAB' is not valid in the grammar.\n",
      "'Aa' is not valid in the grammar.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the grammar rules\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> A B\n",
    "    A -> B A | a\n",
    "    B -> b | A\n",
    "\"\"\")\n",
    "\n",
    "# Define the parse tree\n",
    "parse_tree = nltk.Tree.fromstring(\"\"\"\n",
    "    (S\n",
    "        (A\n",
    "            (B b)\n",
    "            (A a))\n",
    "        (B a))\n",
    "\"\"\")\n",
    "\n",
    "# Define the list of sentential forms to check\n",
    "sentential_forms = [\"baB\", \"Baa\", \"aAB\", \"Aa\"]\n",
    "\n",
    "# Check if each sentential form can be derived\n",
    "for form in sentential_forms:\n",
    "    try:\n",
    "        parser = nltk.ChartParser(grammar)\n",
    "        parsed_trees = list(parser.parse(form))\n",
    "        if parsed_trees:\n",
    "            print(f\"'{form}' can be derived from the grammar.\")\n",
    "        else:\n",
    "            print(f\"'{form}' cannot be derived from the grammar.\")\n",
    "    except ValueError:\n",
    "        print(f\"'{form}' is not valid in the grammar.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parse_tree.png'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Create a Digraph object\n",
    "dot = graphviz.Digraph(format='png')\n",
    "\n",
    "# Add nodes and edges to the Digraph\n",
    "dot.node('S')\n",
    "dot.node('A')\n",
    "dot.node('B')\n",
    "dot.node('B1', label='B')\n",
    "dot.node('A1', label='A')\n",
    "dot.node('a')\n",
    "dot.node('b')\n",
    "\n",
    "dot.edge('S', 'A')\n",
    "dot.edge('S', 'B')\n",
    "dot.edge('A', 'B1')\n",
    "dot.edge('A', 'A1')\n",
    "dot.edge('B1', 'b')\n",
    "dot.edge('A1', 'a')\n",
    "\n",
    "# Render and save the Digraph as a PNG file\n",
    "dot.render('parse_tree', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'baB' is not valid in the grammar.\n",
      "'Baa' is not valid in the grammar.\n",
      "'aAB' is not valid in the grammar.\n",
      "'Aa' is not valid in the grammar.\n",
      "None of the sentential forms satisfy the condition.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (A (B b) (A a)) (B a))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the parse tree\n",
    "parse_tree = nltk.Tree.fromstring(\"\"\"\n",
    "    (S\n",
    "        (A\n",
    "            (B b)\n",
    "            (A a))\n",
    "        (B a))\n",
    "\"\"\")\n",
    "\n",
    "# Function to simplify the parse tree by removing duplicate 'a' under 'A'\n",
    "def simplify_tree(tree):\n",
    "    if isinstance(tree, nltk.Tree):\n",
    "        label = tree.label()\n",
    "        if label == 'A':\n",
    "            children = [simplify_tree(child) for child in tree]\n",
    "            new_children = []\n",
    "            unique_a = False\n",
    "            for child in children:\n",
    "                if child == 'a' and not unique_a:\n",
    "                    unique_a = True\n",
    "                    new_children.append(child)\n",
    "                elif isinstance(child, nltk.Tree):\n",
    "                    new_children.append(child)\n",
    "            return nltk.Tree(label, new_children)\n",
    "        else:\n",
    "            return nltk.Tree(label, [simplify_tree(child) for child in tree])\n",
    "    else:\n",
    "        return tree\n",
    "\n",
    "# Simplify the parse tree\n",
    "simplified_tree = simplify_tree(parse_tree)\n",
    "\n",
    "# Pretty print the simplified tree\n",
    "print(simplified_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'baB' is not valid in the grammar.\n",
      "'Baa' is not valid in the grammar.\n",
      "'aAB' is not valid in the grammar.\n",
      "'Aa' is not valid in the grammar.\n",
      "None of the sentential forms satisfy the condition.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# List of sentential forms to check\n",
    "sentential_forms = [\"baB\", \"Baa\", \"aAB\", \"Aa\"]\n",
    "\n",
    "# Initialize a flag to track if a sentential form is found\n",
    "found = False\n",
    "\n",
    "# Check each sentential form\n",
    "for form in sentential_forms:\n",
    "    try:\n",
    "        # Try to parse the sentential form using the grammar\n",
    "        parser = nltk.ChartParser(grammar)\n",
    "        parsed_trees = list(parser.parse(form))\n",
    "\n",
    "        # Check if the parse tree matches the given parse tree\n",
    "        if parsed_trees and parsed_trees[0] == parse_tree:\n",
    "            print(f\"'{form}' is present in both derivations.\")\n",
    "        else:\n",
    "            print(f\"'{form}' is neither present in the leftmost nor rightmost derivations.\")\n",
    "            found = True\n",
    "    except ValueError:\n",
    "        print(f\"'{form}' is not valid in the grammar.\")\n",
    "\n",
    "if not found:\n",
    "    print(\"None of the sentential forms satisfy the condition.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'baB' is neither leftmost nor rightmost derived.\n",
      "'Baa' is neither leftmost nor rightmost derived.\n",
      "'aAB' is neither leftmost nor rightmost derived.\n",
      "'Aa' is neither leftmost nor rightmost derived.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the parsing tree\n",
    "parse_tree = nltk.Tree.fromstring(\"\"\"\n",
    "    (S\n",
    "        (A\n",
    "            (B b)\n",
    "            (A a))\n",
    "        (B a))\n",
    "\"\"\")\n",
    "\n",
    "# Define the grammar rules\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> A B | B\n",
    "    A -> B A | a\n",
    "    B -> b\n",
    "\"\"\")\n",
    "\n",
    "# Define the sentential forms to check\n",
    "sentential_forms = ['baB', 'Baa', 'aAB', 'Aa']\n",
    "\n",
    "def check_derivation(sentential_form, derivation):\n",
    "    try:\n",
    "        parse_tree = nltk.parse.chart.ChartParser(grammar).parse(sentential_form)\n",
    "        for tree in parse_tree:\n",
    "            if tree == derivation:\n",
    "                return True\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "for form in sentential_forms:\n",
    "    leftmost_derivation = parse_tree.pformat(margin=1000000, nodesep='', parens='[]')\n",
    "    rightmost_derivation = parse_tree.pformat(margin=1000000, nodesep='', parens='[]').replace('[', '<').replace(']', '[').replace('<', ']')\n",
    "\n",
    "    is_leftmost_derived = check_derivation(form, leftmost_derivation)\n",
    "    is_rightmost_derived = check_derivation(form, rightmost_derivation)\n",
    "\n",
    "    if not is_leftmost_derived and not is_rightmost_derived:\n",
    "        print(f\"'{form}' is neither leftmost nor rightmost derived.\")\n",
    "    elif is_leftmost_derived and is_rightmost_derived:\n",
    "        print(f\"'{form}' is both leftmost and rightmost derived.\")\n",
    "    elif is_leftmost_derived:\n",
    "        print(f\"'{form}' is leftmost derived.\")\n",
    "    elif is_rightmost_derived:\n",
    "        print(f\"'{form}' is rightmost derived.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
